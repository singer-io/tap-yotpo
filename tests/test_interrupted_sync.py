from singer.utils import strptime_to_utc
from tap_tester import connections, menagerie, runner
from base import YotpoBaseTest
from tap_tester.logger import LOGGER


class YotpoInterruptedSyncTest(YotpoBaseTest):
    """Test tap sets a bookmark and respects it for the next sync of a stream"""

    def name(self):
        return "tap_tester_yotpo_interrupt_test"

    def test_run(self):
        """
        Scenario: A sync job is interrupted. The state is saved with `currently_syncing`.
                  The next sync job kicks off and the tap picks back up on that `currently_syncing` stream.
        Expected State Structure:
        {
            'currently_syncing': 'product_variants',
            'bookmarks': {
                'collections': {'updated_at':'2022-09-05T14:54:55.000000Z'},
                'emails': {'email_sent_timestamp':'2022-09-06T03:00:10.000000Z'},
                'order_fulfillments':{'1234567890':'2022-09-02T04:32:15.000000Z','1234567890':'2022-09-02T04:32:15.000000Z'},
                'orders': {'updated_at': '2022-09-02T14:18:36.000000Z'},
                'product_reviews':{'1111111111':'2021-01-01T00:00:00.000000Z','2222222222':'2021-01-01T00:00:00.000000Z'},
                'product_variants': {'66666666': '2022-08-05T09:02:07.000000Z', 'currently_syncing': '77777777'},
                'reviews': {'updated_at': '2021-01-01T00:00:00.000000Z'
                }
            }
        }
        Test Cases:
        - Verify an interrupted sync can resume based on the currently_syncing and stream level bookmark value.
        - Verify only records with replication-key values greater than or equal to the stream level bookmark 
          are replicated on the resuming sync for the interrupted stream.
        - Verify the pending streams are replicated following the interrupted stream in the resuming sync. 
        """
        expected_streams = self.expected_streams() - {'product_reviews'}
        expected_replication_keys = self.expected_replication_keys()
        expected_replication_methods = self.expected_replication_method()
        LOGGER.info(f"expected_replication_keys = {expected_replication_keys} \n expected_replication_methods = {expected_replication_methods}")

        ##########################################################################
        # First Sync
        ##########################################################################
        conn_id = connections.ensure_connection(self)

        # Run in check mode
        found_catalogs = self.run_and_verify_check_mode(conn_id)

        # Table and field selection
        catalog_entries = [catalog for catalog in found_catalogs
                           if catalog.get('tap_stream_id') in expected_streams]

        self.perform_and_verify_table_and_field_selection(conn_id, catalog_entries)

        # Run a first sync job using orchestrator
        first_sync_record_count = self.run_and_verify_sync(conn_id)
        first_sync_records = runner.get_records_from_target_output()
        first_sync_bookmarks = menagerie.get_state(conn_id)

        LOGGER.info(f"first_sync_record_count = {first_sync_record_count}")

        ##########################################################################
        # Update State Between Syncs
        ##########################################################################

        LOGGER.info("Current Bookmark after first sync: {}".format(first_sync_bookmarks))

        completed_streams = {'collections', 'emails', 'order_fulfillments', 'orders', 'product_reviews'}
        pending_streams = {'reviews'}
        interrupt_stream = 'product_variants'
        interrupted_sync_states = self.create_interrupt_sync_state(first_sync_bookmarks,
                                                                   interrupt_stream,
                                                                   pending_streams,
                                                                   first_sync_records)
        bookmark_state = interrupted_sync_states["bookmarks"]
        menagerie.set_state(conn_id, interrupted_sync_states)

        LOGGER.info(f"Interrupted Bookmark - {interrupted_sync_states}")

        ##########################################################################
        # Second Sync
        ##########################################################################

        second_sync_record_count = self.run_and_verify_sync(conn_id)
        second_sync_records = runner.get_records_from_target_output()

        second_sync_bookmarks = menagerie.get_state(conn_id)
        LOGGER.info(f"second_sync_record_count = {second_sync_record_count} \n second_sync_bookmarks = {second_sync_bookmarks}")
        ##########################################################################
        # Test By Stream
        ##########################################################################

        for stream in expected_streams:
            LOGGER.info(f"Executing for stream = {stream}")
            with self.subTest(stream=stream):
                # Expected values
                expected_replication_method = expected_replication_methods[stream]

                # Collect information for assertions from syncs 1 & 2 base on expected values
                first_sync_count = first_sync_record_count.get(stream, 0)
                second_sync_count = second_sync_record_count.get(stream, 0)

                # Gather results
                full_records = [message["data"] for message in first_sync_records[stream]["messages"]]
                interrupted_records = [message["data"] for message in second_sync_records[stream]["messages"]]

                first_bookmark_value = first_sync_bookmarks.get('bookmarks', {stream: None}).get(stream)
                second_bookmark_value = second_sync_bookmarks.get('bookmarks', {stream: None}).get(stream)
                LOGGER.info(f"first_bookmark_value = {first_bookmark_value} \n \
                            second_bookmark_value = {second_bookmark_value}")

                if expected_replication_method == self.INCREMENTAL:

                    replication_key = next(iter(expected_replication_keys[stream]))

                    if stream in completed_streams:
                        # Verify at least 1 record was replicated in the second sync
                        self.assertGreaterEqual(second_sync_count,
                                                1,
                                                msg="Incorrect bookmarking for {0}, \
                                                at least one record should be replicated".format(stream))

                    elif stream == interrupted_sync_states.get('currently_syncing', None):
                        # For interrupted stream records sync count should be less equals
                        self.assertLessEqual(second_sync_count,
                                             first_sync_count,
                                             msg="For interrupted stream - {0}, \
                                             seconds sync record count should be less than or equal to first sync".format(stream))

                        # Verify the interrupted sync replicates the expected record set
                        # All interrupted recs are in full recs
                        for record in interrupted_records:
                            self.assertIn(record,
                                          full_records,
                                          msg="incremental table record in interrupted sync not found in full sync")

                        if stream in {'product_reviews', 'product_variants', 'order_fulfillments'}:
                            repl_key = {'product_reviews': 'product_yotpo_id',
                                        'order_fulfillments': 'order_id',
                                        'product_variants': 'yotpo_product_id'}

                            for record in interrupted_records:
                                rec_time = strptime_to_utc(record.get(replication_key))
                                rec_repl_key = str(record[repl_key[stream]])
                                interrupted_stream_state = bookmark_state[stream]
                                if interrupted_stream_state['currently_syncing'] == rec_repl_key:
                                    continue
                                interrupted_bmk = interrupted_stream_state[rec_repl_key]
                                self.assertGreaterEqual(rec_time, strptime_to_utc(interrupted_bmk))
                        else:
                            interrupted_bmk = strptime_to_utc(bookmark_state[stream][replication_key])
                            for record in interrupted_records:
                                rec_time = strptime_to_utc(record.get(replication_key))
                                self.assertGreaterEqual(rec_time, strptime_to_utc(interrupted_bmk))

                            # Record count for all streams of interrupted sync match expectations
                            full_records_after_interrupted_bookmark = 0

                            for record in full_records:
                                rec_time = strptime_to_utc(record.get(replication_key))
                                if rec_time >= strptime_to_utc(interrupted_bmk):
                                    full_records_after_interrupted_bookmark += 1

                            self.assertEqual(full_records_after_interrupted_bookmark,
                                            len(interrupted_records),
                                            msg=f"Expected {full_records_after_interrupted_bookmark} records in each sync",)

                    elif stream in pending_streams:
                        # First sync and second sync record count match
                        self.assertGreaterEqual(second_sync_count,
                                                first_sync_count,
                                                msg="For pending sync streams - {0}, second sync record count \
                                                should be more than or equal to first sync".format(stream))
                    else:
                        raise Exception("Invalid state of stream {0} in interrupted state".format(stream))

                elif expected_replication_method == self.FULL_TABLE:

                    # Verify the syncs do not set a bookmark for full table streams
                    self.assertIsNone(first_bookmark_value)
                    self.assertIsNone(second_bookmark_value)

                    # Verify the number of records in the second sync is the same as the first
                    self.assertEqual(second_sync_count, first_sync_count)
                else:
                    raise NotImplementedError("INVALID EXPECTATIONS\t\tSTREAM: {} \
                                              REPLICATION_METHOD: {}".format(stream, expected_replication_method))
